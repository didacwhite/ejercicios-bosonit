<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Pasos para montar un cluster Hadoop</title>
        <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

/* From extension ms-toolsai.jupyter */
/* These classnames are inherited from bootstrap, but are present in most notebook renderers */

.alert {
    width: auto;
    padding: 1em;
    margin-top: 1em;
    margin-bottom: 1em;
}
.alert > *:last-child {
    margin-bottom: 0;
}
#preview > .alert:last-child {
    /* Prevent this being set to zero by the default notebook stylesheet */
    padding-bottom: 1em;
}

.alert-success {
    /* Note there is no suitable color available, so we just copy "info" */
    background-color: var(--theme-info-background);
    color: var(--theme-info-foreground);
}
.alert-info {
    background-color: var(--theme-info-background);
    color: var(--theme-info-foreground);
}
.alert-warning {
    background-color: var(--theme-warning-background);
    color: var(--theme-warning-foreground);
}
.alert-danger {
    background-color: var(--theme-error-background);
    color: var(--theme-error-foreground);
}

</style>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
        
    </head>
    <body class="vscode-body vscode-light">
        <h1 id="pasos-para-montar-un-cluster-hadoop">Pasos para montar un cluster Hadoop</h1>
<h2 id="descargas-e-instalación-iniciales">Descargas e instalación iniciales</h2>
<ol>
<li>El primer paso es descargar VirtualBox para ejecutar la máquina virtual. Personalmente he elegido descargar Kubuntu, que también hay que descargar desde la página oficial</li>
<li>Una vez descargado, configuramos la máquina virtual configurando manualmente, con los parámetros recomendados, le ponemos de nombre &quot;nodo1&quot; y creamos el usuario hadoop.</li>
<li>Para entrar en usuario root, primero le asignamos una contraseña con el comando <code>sudo passwd root</code> y luego para entrar en este modo escribimos <code>su - root</code>.</li>
<li>Instalar el jdk de java, para comprobar que está todo bien se puede escribir <code>javac</code> o <code>java -version</code>.</li>
</ol>
<h2 id="empieza-la-configuración-hadoop">Empieza la configuración Hadoop</h2>
<ol>
<li>
<p>Antes que nada, se edita el archivo <code>.bashrc</code> de la carpeta personal de usuario (/home/hadoop), y añadimos lo siguiente</p>
<pre><code class="language-sh"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/java/jdkXXXXX
<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$JAVA_HOME</span>/bin
</code></pre>
</li>
<li>
<p>Descarga e instalación de hadoop</p>
<ul>
<li>Acceder como usuario root</li>
<li>Descargar la última versión disponible. En el curso se trabaja con la versión 2, pero descargo la versión 3.</li>
<li>Realizamos la instalación en el directorio <code>/opt</code>, para ello desempaquetamos el fichero en ese directorio <code>tar xvf hadoopXXX-bin.tar</code> y cambiamos el nombre de la carpeta para que quede más limpio <code>mv hadoop-XXXX hadoop</code>.</li>
<li>Comprobamos que está todo bien con <code>ls -l /opt/hadoop</code></li>
<li>Lo más importante: le damos permisos al usuario sobre esta carpeta<pre><code class="language-sh"><span class="hljs-built_in">chown</span> -R hadoop:hadoop hadoop
</code></pre>
</li>
</ul>
</li>
<li>
<p>Volvemos al usuario hadoop y seguimos editando el fichero <code>.bashrc</code>, añadimos:</p>
<pre><code class="language-sh"><span class="hljs-built_in">export</span> HADOOP_HOME=/opt/hadoop
<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:/<span class="hljs-variable">$HADOOP_HOME</span>/bin
<span class="hljs-built_in">export</span> HADOOP_CONF_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/etc/hadoop
</code></pre>
<ul>
<li>Para reiniciar la sesión podemos escribir <code>. ./.bashrc</code></li>
<li>para comprobar que accedemos correctamente: <code>hadoop -h</code> y <code>hadoop version</code></li>
<li>Más adelante para solucionar un error, he tenido que editar el archivo <code>hadoop-env.sh</code> en la carpeta de configuración, seguramente del estilo <code>hadoop/etc/hadoop/hadoop-env.sh</code> <a href="https://stackoverflow.com/questions/8827102/hadoop-error-java-home-is-not-set">solución en stackoverflow</a></li>
</ul>
</li>
<li>
<p>Podemos probar ahora el primer mapreduce, para ello realizamos los siguientes pasos</p>
<pre><code> ```sh
 cd /opt/hadoop
 mkdir /tmp/input
 cp etc/hadoop/*.xml /tmp/input/
 hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.jar grep /tmp/input /tmp/output 'dfs[a-z.]+'
 ls -l /tmp/output/
 ```
</code></pre>
</li>
</ol>
<h2 id="configurar-ssh">Configurar SSH</h2>
<ol>
<li>Entramos como usuario hadoop y creamos las claves con <code>ssh-keygen</code>.  Esto habrá creado un directorio denominado /home/hadoop/.ssh (si no existía
ya) y habrá creado dos ficheros con las clave pública y la privada.</li>
<li>Realizamos lo siguiente:<pre><code class="language-sh"><span class="hljs-built_in">cd</span> .ssh
<span class="hljs-built_in">cp</span> id_rsa.pub authorized_keys
</code></pre>
Esto habría que hacerlo en todos los nodos, de momento solo tenemos uno</li>
<li>Comprobamos que tenemos acceso con <code>ssh nodo1</code> y podemos salir escribiendo <code>exit</code>.</li>
</ol>
<h2 id="instalación-pseudodistribuida">Instalación pseudodistribuida</h2>
<ol>
<li>Accediendo como root, creamos el directorio <code>mkdir /datos</code> y le damos permisos al usuario hadoop <code>chown hadoop:hadoop /datos</code>. Volvemos a logear como hadoop.</li>
<li>Acceder a <code>/opt/hadoop/etc/hadoop</code>, vamos a cambiar unas cuantas configuraciones.
<ol>
<li>En el archivo <code>core-site.xml</code>, agregar:<pre><code class="language-js">&lt;configuration&gt;
    <span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://nodo1:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span>
&lt;/configuration&gt;
</code></pre>
</li>
<li>Editamos el archivo <code>hdfs-site.xml</code>, como solo tenemos un nodo, ponemos 1 en factor de replicación.<pre><code class="language-js">&lt;configuration&gt;
    <span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span>
    <span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/datos/namenode<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span>
    <span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/datos/datanode<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span>
&lt;/configuration&gt;
</code></pre>
</li>
</ol>
</li>
<li>Creamos ahora los directorios para el sistema de archivos, no se tienen por qué llamar así pero les ponemos este nombre para que quede más claro (se incluyen en la configuración), tampoco es necesario crear las carpetas pero nos evita problemas de permisos.<pre><code class="language-sh"><span class="hljs-built_in">mkdir</span> /datos/namenode
<span class="hljs-built_in">mkdir</span> /datos/datanode
</code></pre>
</li>
<li>Formateamos el sistema de ficheros que acabamos de crear: <code>dfs namenode -format</code>. Si todo es correcto, deberíamos tener un directorio en cada carpeta denominado <code>current</code>.</li>
</ol>
<h2 id="arrancamos-hdfs">Arrancamos HDFS</h2>
<ol>
<li>Para arrancar los procesos, debe arrancar <strong>NAMENODE</strong>, <strong>SECONDARY NAMENODE</strong> y <strong>DATANODE</strong>.<pre><code class="language-sh">start-dfs.sh
</code></pre>
</li>
<li>Con el comando <code>jps</code> podemos comprobar los procesos en ejecución.</li>
</ol>
<ul>
<li><a href="http://nodo1:9870">http://nodo1:9870</a></li>
<li><a href="http://nodo1:8088">http://nodo1:8088</a></li>
</ul>
<ol start="3">
<li>Para tareas como realizar un checkpoint, podemos entrar en modo seguro. Se puede comprobar en el directorio /datos/namenode por ejemplo.<pre><code class="language-sh">hdfs dfsadmin -safemode enter
hdfs dfsadmin -saveNamespace
hdfs dfsadmin -safemode leave
</code></pre>
</li>
</ol>
<h2 id="administración-de-hdfs">Administración de HDFS</h2>
<ol>
<li>Podemos realizar un report del sistema <code>hdfs dfsadmin -report</code></li>
<li>Comprobar con hdfs fsck el estado del sistema de ficheros o de un directorio concreto <code>hdfs fsck /</code></li>
<li>La topología actual <code>hdfs dfsadmin -printTopology</code></li>
<li>Y comprobar si hay algún fichero abierto <code>hdfs dfsadmin -listOpenFiles</code></li>
</ol>
<h2 id="snapshots">Snapshots</h2>
<ol>
<li>Permitimos la creación de snapshots en el directorio que queramos <code>hdfs dfsadmin -allowSnapshot /datos4</code></li>
<li>Creamos un snapshot llamado s1 en el directorio <code>hdfs dfs -createSnapshot /datos4 s1</code></li>
<li>Comprobamos que se ha creado satisfactoriamente <code>hdfs dfs -ls /datos4/.snapshot</code></li>
<li>Una vez modificado el original, para recuperar el snapshot podemos escribir <code>hadoop fs -cp /datos4/.snapshot/s1/f1.txt /datos4/</code></li>
</ol>
<h2 id="yarn-en-entornos-pseudodistribuídos">Yarn en entornos pseudodistribuídos</h2>
<h3 id="configuración">Configuración</h3>
<ol>
<li>El curso manda copiar el archivo mapred-site.xml.template, en mi caso ya lo tengo creeado sin .template</li>
<li>Ponemos la siguiente propiedad<pre><code class="language-js">&lt;property&gt;
    <span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span>
    <span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span>
&lt;/property&gt;
</code></pre>
</li>
<li>En el fichero yarn-site.xml ponemos (<a href="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/yarn-service/QuickStart.html#Configure_and_start_HDFS_and_YARN_components%20y%20https://programmerclick.com/article/8992195719/">link</a>). Para obtener el classpath escribir <code>hadoop classpath</code><pre><code class="language-js">&lt;configuration&gt;

&lt;!-- <span class="hljs-title class_">Site</span> specific <span class="hljs-variable constant_">YARN</span> configuration properties --&gt;
<span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>
    Enable services rest api on ResourceManager.
    <span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.webapp.api-service.enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span>

<span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.application.classpath<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span>

&lt;/configuration&gt;
</code></pre>
<blockquote>
<p>CHOQUE CON CURSO, ESTO PUEDE SER CAUSA DE ERROR, OTRA OPCIÓN ES</p>
</blockquote>
<pre><code class="language-JS">&lt;property&gt;
    <span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span>
    <span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>nodo1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span>
&lt;/property&gt;
<span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span>
<span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services
    .mapreduce_shuffle.class<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></span>
</code></pre>
<blockquote>
<p>Esto ha sido importante para que funcionen todos los nodos, a esto se refiere en el siguiente punto. Para comprobar que los nodos están funcionando, se puede ejecutar <code>yarn node -list</code></p>
</blockquote>
</li>
<li>Seguramente haya que añadir más datos si el entorno no es pseudodistribuído, ver pdf del curso</li>
</ol>
<h3 id="ejemplo-de-yarn">Ejemplo de Yarn</h3>
<ol>
<li>
<p>Después de arrancar hdfs, ejecutramos <code>start-yarn.sh</code></p>
</li>
<li>
<p>Comprobamos que sale el proceso yarn si escribimos <code>jps</code></p>
</li>
<li>
<p>Para guardar el registro de jobs lanzados podemos usar <code>mapred --daemon start historyserver</code></p>
</li>
<li>
<p>Es posible que en hadoop3 no funcione correctamente el yarn, puede ser que haya que añadir a yarn-site.xml</p>
<pre><code class="language-js">&lt;property&gt;
<span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.application.classpath<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span></span>
<span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>
/opt/hadoop3/hadoop/etc/hadoop,
/opt/hadoop3/share/hadoop/common/*,
/opt/hadoop3/share/hadoop/common/lib/*,
/opt/hadoop3/share/hadoop/hdfs/*,
/opt/hadoop3/share/hadoop/hdfs/lib/*,
/opt/hadoop3/share/hadoop/mapreduce/*,
/opt/hadoop3/share/hadoop/mapreduce/lib/*,
/opt/hadoop3/share/hadoop/yarn/*,
/opt/hadoop3/share/hadoop/yarn/lib/*
<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span></span>
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>Para esta prueba, descargamos por ejemplo el libro del quijote y lo introducimos en el sistema de ficheros de hdfs <code>hdfs dfs -put /home/hadoop/Descargas/quijote.txt /practica</code></p>
</li>
<li>
<p><code>hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.0.jar wordcount /practicas/quijote.txt /practicas/resultado</code></p>
</li>
<li>
<p>Comprobamos el resultado en <code>hdfs dfs -ls /practicas/resultado</code></p>
</li>
<li>
<p><code>hdfs dfs -get /practicas/resultado/part-r-00000 /tmp/palabras_quijote.txt</code></p>
</li>
<li>
<p>Recordar que en la web de YARN podemos ver información muy interesante sobre el job.</p>
</li>
</ol>
<h2 id="creación-de-cluster-real">Creación de cluster real</h2>
<ol>
<li>Antes de clonar la máquina virtual, se añade en configuración otra tarjeta de red con red interna.</li>
<li>Clonamos la máquina virtual fijandose en el directorio donde se va a guardar y que cree nuevas direcciones MAC, y cambiamos el hostname por dos vías en los 3 nodos,<pre><code class="language-sh">sudo hostname nodo2
sudo nano /etc/hostname
sudo nano /etc/hosts
</code></pre>
<img src="file:///c:\Users\didac.blanco\Documents\recursos\BIG DATA\repo ejercicios\creación de cluster hadoop\img\hosts.png" alt="hosts"><pre><code class="language-sh">sudo reboot
</code></pre>
</li>
<li>Configuración de red:
<ol>
<li>Parámetro ipv4 ponerlo en manual</li>
<li>Escribir las ips, puerta de enlace no tan importante
<img src="file:///c:\Users\didac.blanco\Documents\recursos\BIG DATA\repo ejercicios\creación de cluster hadoop\img\ipsetup.png" alt="ipsetup"></li>
<li>En los 3 nodos hacer un rm * en el directorio /.ssh</li>
<li>Efectuar el siguiente bucle
<ul>
<li>ssh-keygen</li>
<li>cp id_rsa.pub authorized_keys</li>
<li>scp authorized_keys nodo2:/home/hadoop/.ssh</li>
<li>ssh nodo2</li>
<li>ssh-keygen</li>
<li>cat id_rsa.pub &gt;&gt; authorized_keys</li>
<li>scp authorized_keys nodo3:/home/hadoop/.ssh</li>
<li>ssh nodo3</li>
<li>...</li>
</ul>
</li>
<li>Tendremos un archivo authorized_keys duplicado en todos los nodos</li>
<li>Para terminar habría que <code>chmod 0600 authorized_keys</code></li>
</ol>
</li>
<li>Editar los archivos de configuración
<ol>
<li><code>cd /datos/datanode</code> debería estar vacío en los esclavos y <code>namenode</code> no debería existir</li>
<li>en el maestro borrar <code>datanode</code> y no hace falta vaciar <code>namenode</code>, habría que hacer únicamente un <code>-format</code></li>
<li>editar hdfs-site.xml para cambiar el número de replicación (a 2) y copiarlo al resto de nodos</li>
<li>editar archivo <code>workers</code> y escribir nodo2 y nodo3</li>
</ol>
</li>
</ol>
<h2 id="hive">Hive</h2>
<ul>
<li>Nota: Para ejecutar hive la versión 11 de java no es compatible, así que es conveniente usar java 8 desde el principio, para hacer <a href="https://askubuntu.com/questions/1133216/downgrading-java-11-to-java-8">downgrade</a></li>
<li>Después del downgrade, editar los archivos .bashrc y <a href="http://hadoop-env.sh">hadoop-env.sh</a> en todos los nodos para tener bien el path</li>
</ul>
<ol>
<li>
<p>Instalar hive en /opt/hadoop/hive y volver a editar .bashrc</p>
<pre><code>export PDSH_RCMD_TYPE=ssh
export HADOOP_HOME=/opt/hadoop
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HIVE_HOME=/opt/hadoop/hive
export ZOOKEEPER_HOME=/opt/hadoop/zoo
export PATH=$PATH:$JAVA_HOME/bin:$HIVE_HOME/bin:$ZOOKEEPER_HOME/bin
</code></pre>
<p>recordar que se puede volver a ejecutar con <code>. /.bashrc</code></p>
</li>
<li>
<p>Archivos de configuración, seguir los siguientes pasos:</p>
<ul>
<li>cd /opt/hadoop/hive/conf</li>
<li>cp hive-default.xml-template hive-site.xml</li>
<li>cp hive-env.sh.template <a href="http://hive-env.sh">hive-env.sh</a></li>
<li>cp hive-exec-log4j2.propierties.template hive-exec-log4j2.propierties</li>
<li>cp hive-log4j2.propierties.template hive-log4j2.propierties</li>
<li>cp beeline-log4j2.propierties.template beeline-log4j2.propierties</li>
<li>nano <a href="http://hive-env.sh">hive-env.sh</a>
<ul>
<li>export HADOOP_HOME=/opt/hadoop</li>
<li>export HIVE_CONF_DIR=/opt/hadoop/hive/conf</li>
</ul>
</li>
<li>hdfs dfs -mkdir /tmp (ya debería estar creado)</li>
<li>hdfs dfs -mkdir -p /user/hive/warehouse</li>
<li>hdfs dfs -chmod g+w /tmp</li>
<li>hdfs dfs -chmod g+w /user/hive/warehouse
Hive ya estaría listo para su utilización.</li>
</ul>
</li>
<li>
<p>para poder utilizar hive a modo de prueba, ejecutar primero: <code>schematool -initSchema -dbType derby</code></p>
</li>
</ol>
<p>si no funciona, utilizar antes <code>mv metastore_db metastore_db.tmp</code> <a href="https://www.edureka.co/community/63178/error-function-nucleus-ascii-already-exists">link</a></p>
<p>Nos encontramos con el problema del yarn al ejecutar un job ya que no había nodos disponibles, solucionado y escrito en el punto correspondiente. Al hacer esto con el metastore ya inicializado, hizo falta reiniciar todo el sistema y por esto lo escrito antes de este párrafo. Nada grave, continuamos.</p>
<h2 id="beeline">Beeline</h2>
<p>Para poder conectarse en remoto, hay que editar el archivo
cd /opt/hadoop/hive/conf
kate hive-site.xml
editar hive.server2.enable.doAs
y poner value=false</p>
<p>he tenido que reiniciar para que funcione</p>

        <script async src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>
        
    </body>
    </html>